{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319a0b43",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a081717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs # for manipulating xml files\n",
    "import os # for manipulating files and directories in the operating system\n",
    "import pandas as pd # for manipulating dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b0291",
   "metadata": {},
   "source": [
    "## Create a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14e40d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "{\"Text\" :  [ ],\"Filler\" :  [ ],\n",
    " \"Repetition\" :  [ ],\"Japanese_Word\" :  [ ],\n",
    " \"Unfinished_Sentence\" :  [ ],\"Self-Correction\" :  [ ],\n",
    " \"Short_Pause\" :  [ ],\"Long_Pause\" :  [ ], \"SST_LEVEL\" :  [  ]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49597ec",
   "metadata": {},
   "source": [
    "## Converting the files into a single csv dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17daa207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text  Filler  Repetition  \\\n",
      "0     My name is . Hello.  I'm fine, but I'm a littl...   188.0        68.0   \n",
      "1      I'm . Nice to meet you. Yes, of course.  I li...   138.0        74.0   \n",
      "2     My name is . O K. Please call me .  Yes. I wor...   105.0        35.0   \n",
      "3     My name is . Thank you. Nice to meet you.  I l...   136.0        34.0   \n",
      "4       my name is . Nice to meet you, too. . I work...   303.0        49.0   \n",
      "...                                                 ...     ...         ...   \n",
      "1276  O K. My name is . Nice to meet you.  fine. But...   117.0        17.0   \n",
      "1277  . Good morning.  I'm . Sure.  I'm a little tir...   159.0        16.0   \n",
      "1278  My name is . Call me . Yes. I'm fine. Bit nerv...   140.0        41.0   \n",
      "1279   my name is . Sure. Fine, thank you. How about...   137.0         7.0   \n",
      "1280  My name is . Yeah. O K. How are you? I live in...    99.0        45.0   \n",
      "\n",
      "      Japanese_Word  Unfinished_Sentence  Self-Correction  Short_Pause  \\\n",
      "0               2.0                  3.0             38.0         17.0   \n",
      "1               1.0                  0.0             18.0         31.0   \n",
      "2               0.0                  0.0             21.0         80.0   \n",
      "3               3.0                  0.0             47.0         81.0   \n",
      "4               1.0                  0.0             38.0         55.0   \n",
      "...             ...                  ...              ...          ...   \n",
      "1276            0.0                  1.0             25.0          1.0   \n",
      "1277            1.0                  2.0             45.0          0.0   \n",
      "1278            3.0                  1.0             29.0          2.0   \n",
      "1279            0.0                  5.0             29.0          3.0   \n",
      "1280            1.0                  2.0             59.0         10.0   \n",
      "\n",
      "      Long_Pause SST_LEVEL  \n",
      "0            4.0         4  \n",
      "1            4.0         5  \n",
      "2            0.0         5  \n",
      "3            0.0         4  \n",
      "4            0.0         4  \n",
      "...          ...       ...  \n",
      "1276         0.0         9  \n",
      "1277         0.0         9  \n",
      "1278         1.0         9  \n",
      "1279         1.0         9  \n",
      "1280         3.0         7  \n",
      "\n",
      "[1281 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(r\"DatasetModifiedTags\"): # loop through each of the xml files inside the directory: DatasetModifiedTags\n",
    "   with open(os.path.join(r\"DatasetModifiedTags\", filename), 'r') as f: \n",
    "\n",
    "       content = []\n",
    "       content = f.readlines()\n",
    "       content = \"\".join(content)\n",
    "       bsc = bs(content, \"lxml\") #using the beautifulsoup library to read the content of each file\n",
    "\n",
    "       f.close()\n",
    "        \n",
    "       #remove unnecessary interviewer speech\n",
    "        \n",
    "       interviewer = bsc.find_all(\"a\")\n",
    "       for item in interviewer:\n",
    "            item.decompose()\n",
    "\n",
    "    \n",
    "       \n",
    "        \n",
    "         #get some useful features from the learner speech\n",
    "       filler_number = len(bsc.find_all(\"f\"))      #get the number of <f> tags (filled pause)\n",
    "       repetition_number = len(bsc.find_all(\"r\"))  #get the number of <r> tags (repetition)\n",
    "       jp_word_number = len(bsc.find_all(\"jp\"))    #get the number of <jp> tags (use of japanese word)\n",
    "       spause_number = len(bsc.find_all(\"d\"))      #get the number of <d> tags  (short pause)\n",
    "       lpause_number = len(bsc.find_all(\"dd\"))     #get the number of <dd> tags (long pause)\n",
    "       co_number = len(bsc.find_all(\"co\"))         #get the number of <co> tags (cut-off or unfinished sentence) \n",
    "       sc_number = len(bsc.find_all(\"sc\"))         #get the number of <sc> tags (self-correction)\n",
    "\n",
    "       \n",
    "        \n",
    "       #remove unnecessary tags in the raw text like repetitions, non verbal signs etc.. \n",
    "       removed_tags = bsc.find_all(\n",
    "           [\"nvs\", \"ctxt\", \"r\", \"rq\", \"sc\", \"scq\",\"h\", \"co\", \"f\"]) \n",
    "        \n",
    "       for item in removed_tags:\n",
    "           item.decompose()  # the decompose function destroys the object (tag + its content)\n",
    "            \n",
    "       \n",
    "       learner = bsc.find_all(\"b\")  # all the learner speech data is now in a list\n",
    "\n",
    "       level = bsc.find_all(\"sst_level\")  # the target data (sst english level)\n",
    "     \n",
    "       elements = [l.get_text() for l in learner]\n",
    "       text = \" \".join(elements)  # text variable now contains all the text in a string instead of a list\n",
    "            \n",
    "            #create a row to insert in the dataframe\n",
    "       new_row = {\"Text\": text, \"Filler\": filler_number,\n",
    "              \"Repetition\": repetition_number, \"Japanese_Word\": jp_word_number, \"Unfinished_Sentence\": co_number,\n",
    "              \"Self-Correction\": sc_number, \"Short_Pause\": spause_number, \"Long_Pause\": lpause_number\n",
    "              , \"SST_LEVEL\": level[0].get_text()} \n",
    "        \n",
    "\n",
    "       df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv(\"LearnerDataset.csv\",index=False) #save the dataframe into a .csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
